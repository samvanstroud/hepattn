seed_everything: 42
name: TRK-MAIN-SCALEUP-VERSION-epochs30-MA-eta2p5-pt600-hepformer-tracker-initnet-hepattn-decoder-hepf-layer

data:
  train_dir:  /share/rcif2/pduckett/data/prepped/train/
  val_dir: /share/rcif2/pduckett/data/prepped/val/
  test_dir: /share/rcif2/pduckett/data/prepped/test/

  hit_eval_train: /share/rcif2/pduckett/data/prepped/filter_evals/eta2p5pt600/epoch=100-val_loss=0.15778_train_eval.h5
  hit_eval_val: /share/rcif2/pduckett/data/prepped/filter_evals/eta2p5pt600/epoch=100-val_loss=0.15778_val_eval.h5
  hit_eval_test: /share/rcif2/pduckett/data/prepped/filter_evals/eta2p5pt600/epoch=100-val_loss=0.15778_test_eval.h5

  num_workers: 10
  num_train: -1
  num_test: -1
  num_val: -1

  # Select only hits from these detector volumes
  # pix barrel: 8, pix endcap: 7, 9
  # See: https://competitions.codalab.org/competitions/20112
  hit_volume_ids: [7, 8, 9]


  # Minimum pt for a particle to be deemed reconstructible
  particle_min_pt: 0.6

  # Maximum absolute eta for a particle to be deemed reconstructible
  particle_max_abs_eta: 2.5

  # Minimum number of true hits for a particle to be deemed reconstructible
  particle_min_num_hits: 3

  # Maximum number of reconstructable particles allowed in an event
  event_max_num_particles: &num_objects 2100

  # Define which inputs will be available to the model
  inputs:
    hit:
      # Global hit coords
      - x
      - y
      - z
      - r
      - s
      - eta
      - phi
      - theta
      - u
      - v
      # Hit local charge information
      - charge_frac
      - leta
      - lphi
      - lx
      - ly
      - lz
      - geta
      - gphi

  targets:
    particle:
      - pt
      - eta
      - phi
      - px
      - py
      - pz
      - p

trainer:
  # Training stuff here
  max_epochs: 10
  accelerator: gpu
  devices: 1
  precision: bf16-mixed
  log_every_n_steps: 10
  default_root_dir: logs
  gradient_clip_val: 0.1
  enable_progress_bar: true

  logger:
    class_path: hepattn.utils.loggers.MyCometLogger
    init_args:
      project: trackml_tracking
      log_env_details: true

  callbacks:
    # - class_path: hepattn.callbacks.Compile
    - class_path: hepattn.callbacks.InferenceTimer
    - class_path: hepattn.callbacks.SaveConfig
    - class_path: hepattn.callbacks.Checkpoint
      init_args:
        monitor: val/loss
    - class_path: hepattn.callbacks.PredictionWriter
      init_args:
        write_inputs: false
        write_outputs: true
        write_preds: true
        write_targets: true
        write_losses: false
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
    - class_path: lightning.pytorch.callbacks.TQDMProgressBar
      init_args:
        refresh_rate: 1

model:
  optimizer: Lion

  # Learning rate scheduler config
  lrs_config:
    initial: 1e-5
    max: 5e-5
    end: 1e-5
    pct_start: 0.05
    skip_scheduler: false
    weight_decay: 1e-5

  # Whether to use multi task learning or not
  mtl: false

  log_metrics_train: True
  
  model:
    class_path: hepattn.models.maskformer.FilterTracker
    init_args:
      loss_config:
        adaptive_lap: true
        num_classes: 1
        num_objects: *num_objects
        null_class_weight: 1.0
        loss_weights:
          object_class_ce: 0.1
          mask_focal: 50.0
          mask_dice: 2.0
          regression: 0.1
      input_net:
        class_path: hepattn.models.hepformer_initnet.InitNet
        init_args:
          name: hit
          fields:
            - x
            - y
            - z
            - r
            - s
            - eta
            - phi
            - u
            - v
            - charge_frac
            - leta
            - lphi
            - lx
            - ly
            - lz
            - geta
            - gphi
          net:
            class_path: hepattn.models.Dense
            init_args:
              input_size: 17
              output_size: 256
              hidden_layers:
              - 256
              hidden_dim_scale: 2
              activation: torch.nn.SiLU
              final_activation: null
              dropout: 0.0
          pos_enc:
            class_path: hepattn.utils.hepformer_positional_enc.PositionalEncoder
            init_args:
              variables:
              - phi
              - theta
              - r
              dim: 256
              alpha: 2000
      mask_decoder:
        class_path: hepattn.models.hepattn_decoder.MaskFormerDecoder
        init_args:
          num_decoder_layers: 8
          num_queries: *num_objects
          dim: 256
          decoder_layer_type: hepformer
          decoder_layer_config:
            mask_attention: true
            local_ca: false
            bidirectional_ca: true
            n_heads: 8
          mask_attention: true
          mask_net:
            class_path: hepattn.models.Dense
            init_args:
              input_size: 256
              output_size: 256
              hidden_layers: null
              hidden_dim_scale: 2
              activation: torch.nn.SiLU
              final_activation: null
              dropout: 0.0
          class_net:
            class_path: hepattn.models.Dense
            init_args:
              input_size: 256
              output_size: 1
              hidden_layers: null
              hidden_dim_scale: 2
              activation: torch.nn.SiLU
              final_activation: null
              dropout: 0.0
          aux_loss: true
      encoder:
        class_path: hepattn.models.Encoder
        init_args:
          num_layers: 12
          dim: 256
          attn_type: flash
          window_size: 512
          window_wrap: true
          hybrid_norm: true
          norm: RMSNorm

      # matcher:
      #   class_path: hepattn.models.matcher.Matcher
      #   init_args:
      #     default_solver: scipy
      #     adaptive_solver: true